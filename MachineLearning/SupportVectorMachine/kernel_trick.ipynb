{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Kernel-Trick\" data-toc-modified-id=\"Kernel-Trick-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Kernel Trick</a></span><ul class=\"toc-item\"><li><span><a href=\"#Higher-Dimension\" data-toc-modified-id=\"Higher-Dimension-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Higher Dimension</a></span></li></ul></li><li><span><a href=\"#Kernel-Discussion\" data-toc-modified-id=\"Kernel-Discussion-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Kernel Discussion</a></span><ul class=\"toc-item\"><li><span><a href=\"#RBF---Radius-Basis-Kernel\" data-toc-modified-id=\"RBF---Radius-Basis-Kernel-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>RBF - Radius Basis Kernel</a></span><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Motivation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Intro-Situation\" data-toc-modified-id=\"Intro-Situation-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>Intro Situation</a></span></li><li><span><a href=\"#Intro-Situation---One-Function\" data-toc-modified-id=\"Intro-Situation---One-Function-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>Intro Situation - One Function</a></span></li></ul></li><li><span><a href=\"#Intro-Situation---One-Function\" data-toc-modified-id=\"Intro-Situation---One-Function-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Intro Situation - One Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Adding-more-points\" data-toc-modified-id=\"Adding-more-points-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>Adding more points</a></span></li><li><span><a href=\"#Q:-What-would-it-look-like-for-5-different-points?\" data-toc-modified-id=\"Q:-What-would-it-look-like-for-5-different-points?-2.1.2.2\"><span class=\"toc-item-num\">2.1.2.2&nbsp;&nbsp;</span>Q: What would it look like for 5 different points?</a></span></li><li><span><a href=\"#Q:-What-about-an-additional-point-(not-easily-separable)?\" data-toc-modified-id=\"Q:-What-about-an-additional-point-(not-easily-separable)?-2.1.2.3\"><span class=\"toc-item-num\">2.1.2.3&nbsp;&nbsp;</span>Q: What about an additional point (not easily separable)?</a></span></li></ul></li><li><span><a href=\"#How-This-Is-Helpful?\" data-toc-modified-id=\"How-This-Is-Helpful?-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>How This Is Helpful?</a></span></li></ul></li><li><span><a href=\"#Note-on-Hyperparameter-$\\gamma$\" data-toc-modified-id=\"Note-on-Hyperparameter-$\\gamma$-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Note on Hyperparameter $\\gamma$</a></span></li><li><span><a href=\"#Scikit-Learn-Example\" data-toc-modified-id=\"Scikit-Learn-Example-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Scikit Learn Example</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a simple model isn't good enough, extend to higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(consider a line with no good cut; extend to parabola)\n",
    "(consider a 2D → 3D & EQUIVALENT making a higher degree polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider all the possible ways to combine:\n",
    "\n",
    "2D → 5D\n",
    "$x,y --> (x,y,x^2,xy,y^2)$\n",
    "\n",
    "2d separator <-- Get a 4D separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel describes the mapping/transformation\n",
    "\n",
    "With polynomial kernel, we get more options to try (vs linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Kernel Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> A **kernel** is really a way to split the data into different parts\n",
    "\n",
    "A common one for SVMs is **RBF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## RBF - Radius Basis Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Intro Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine two points and we defined, we can generate a function for each point\n",
    "![](images/rbf_2_separated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Intro Situation - One Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/rbf_2_combined.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Adding more points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/rbf_3_combined.png)\n",
    "![](images/rbf_3_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Q: What would it look like for 5 different points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/rbf_5_open.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Q: What about an additional point (not easily separable)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/rbf_6_open.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### How This Is Helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> We can use the hills and valleys to separate the points!\n",
    "\n",
    "Record the heights over each point for each RBF\n",
    "\n",
    "This turns into a vector (higher dimensional space) → likely separable\n",
    "\n",
    "Uses hyperplane to get the weights\n",
    "\n",
    "![https://www.researchgate.net/figure/Figure-B16-Non-linear-classifier-using-Kernel-trick_fig13_324250451](images/kernel_trick_hyperdimensional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Note on Hyperparameter $\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$\\gamma$ hyperparameter gives narrow/fat (big/small $\\gamma$) \n",
    "\n",
    "This essentially allows us to get less/more overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Scikit Learn Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T19:54:07.917371Z",
     "start_time": "2019-08-27T19:54:03.659180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Utility function to move the midpoint of a colormap to be around\n",
    "# the values of interest.\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "# #############################################################################\n",
    "# Load and prepare data set\n",
    "#\n",
    "# dataset for grid search\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dataset for decision function visualization: we only keep the first two\n",
    "# features in X and sub-sample the dataset to keep only 2 classes and\n",
    "# make it a binary classification problem.\n",
    "\n",
    "X_2d = X[:, :2]\n",
    "X_2d = X_2d[y > 0]\n",
    "y_2d = y[y > 0]\n",
    "y_2d -= 1\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "# #############################################################################\n",
    "# Train classifiers\n",
    "#\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Now we need to fit a classifier for all parameters in the 2d version\n",
    "# (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_2d, y_2d)\n",
    "        classifiers.append((C, gamma, clf))\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "#\n",
    "# draw visualization of parameter effects\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # visualize decision function for these parameters\n",
    "    plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu_r,\n",
    "                edgecolors='k')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "\n",
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "#\n",
    "# The score are encoded as colors with the hot colormap which varies from dark\n",
    "# red to bright yellow. As the most interesting scores are all located in the\n",
    "# 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "# as to make it easier to visualize the small variations of score values in the\n",
    "# interesting range while not brutally collapsing all the low score values to\n",
    "# the same color.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
