{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#â™«-harder,-better,-faster,-stronger-â™«\" data-toc-modified-id=\"â™«-harder,-better,-faster,-stronger-â™«-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>â™« harder, better, faster, stronger â™«</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-useful-resources-on-optimization\" data-toc-modified-id=\"Some-useful-resources-on-optimization-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Some useful resources on optimization</a></span></li></ul></li><li><span><a href=\"#Vanishing-Gradient-Problem\" data-toc-modified-id=\"Vanishing-Gradient-Problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Vanishing Gradient Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#Activation-functions-(from-before)\" data-toc-modified-id=\"Activation-functions-(from-before)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Activation functions (from before)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recall-what-an-activation-function-does\" data-toc-modified-id=\"Recall-what-an-activation-function-does-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Recall what an activation function does</a></span></li><li><span><a href=\"#Using-the-proper-activation\" data-toc-modified-id=\"Using-the-proper-activation-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Using the proper activation</a></span></li></ul></li><li><span><a href=\"#Random-Starts\" data-toc-modified-id=\"Random-Starts-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Random Starts</a></span></li><li><span><a href=\"#Momentum\" data-toc-modified-id=\"Momentum-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Momentum</a></span><ul class=\"toc-item\"><li><span><a href=\"#Solution?--Give-it-some-speed-ðŸ˜Ž\" data-toc-modified-id=\"Solution?--Give-it-some-speed-ðŸ˜Ž-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Solution?  Give it some speed ðŸ˜Ž</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Implementation\" data-toc-modified-id=\"Code-Implementation-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Code Implementation</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Make-it-Go-Faster-with-Optimizers!\" data-toc-modified-id=\"Make-it-Go-Faster-with-Optimizers!-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Make it Go Faster with Optimizers!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalization-(Batch-Normalization)\" data-toc-modified-id=\"Normalization-(Batch-Normalization)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Normalization (Batch Normalization)</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent\" data-toc-modified-id=\"Stochastic-Gradient-Descent-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Stochastic Gradient Descent</a></span><ul class=\"toc-item\"><li><span><a href=\"#Steps\" data-toc-modified-id=\"Steps-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Steps</a></span></li></ul></li><li><span><a href=\"#AdaGrad-&amp;-RMSProp\" data-toc-modified-id=\"AdaGrad-&amp;-RMSProp-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>AdaGrad &amp; RMSProp</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Example\" data-toc-modified-id=\"Code-Example-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Code Example</a></span></li></ul></li><li><span><a href=\"#Adam-(Adaptivr-Moment-Estimation)-Optimization-and-Other-Variants\" data-toc-modified-id=\"Adam-(Adaptivr-Moment-Estimation)-Optimization-and-Other-Variants-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Adam (Adaptivr Moment Estimation) Optimization and Other Variants</a></span></li><li><span><a href=\"#Learning-Rate-Decay\" data-toc-modified-id=\"Learning-Rate-Decay-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Learning Rate Decay</a></span><ul class=\"toc-item\"><li><span><a href=\"#Solution?\" data-toc-modified-id=\"Solution?-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Solution?</a></span></li><li><span><a href=\"#Code-Example\" data-toc-modified-id=\"Code-Example-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Code Example</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# â™« harder, better, faster, stronger â™«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can optimize our model to run faster and better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sometimes this optimization feels like black magic over a science...\n",
    "\n",
    "![https://xkcd.com/1838/](images/machine_learning_xkcd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Some useful resources on optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Keras documentation & discussion: https://keras.io/optimizers/\n",
    "- Excellent blog post on optimizations: http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Vanishing Gradient Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When our gradients are too small we can run into a few issues when training our model (adjusting weights and biases):\n",
    "- Slow training\n",
    "- Local minimum problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Activation functions (from before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Recall what an activation function does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "![](images/relu_bouncer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Using the proper activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A simple way to change the gradient, is change the activation function that produces different gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/activations_ranked.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In general:\n",
    "\n",
    "* Sigmoid should almost never be used anymore for an activation \n",
    "* ReLU is a good balance of speed and performance (most systems have optimizations)\n",
    "* You may find other variants like leaky ReLU to give better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To avoid local minimums, what if we just randomly initialize ourselves somewhere on the cost function?\n",
    "\n",
    "We'll have to run the same model multiple times, but we start off with different weights and can help avoid falling into a local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recall gradient descent is analogous to finding the lowest point of the cost function ($J$) by adjusting the weights $W$ by the gradient of the cost function (multiplied by the learning factor)\n",
    "\n",
    "$$ W \\leftarrow W - \\alpha \\nabla J(W) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/cartoon_descender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But sometimes we can get \"trapped\" in a **local minimum**, a spot that is low compared to the nearby area but not the lowest point overall. Think of a ball rolling down the hill getting stuck at a plateau or slight incline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Solution?  Give it some speed ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can \"power\" over the hill with **momentum**; the gradient term of our weights update will be our _acceleration_:\n",
    "\n",
    "$$ V_m \\leftarrow \\beta V_m - \\alpha \\nabla J(W) $$\n",
    "$$ W \\leftarrow W + V_m $$\n",
    "\n",
    "where $\\beta$ is our momentum hyperparameter (usually set to about 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In addition to going up the hill, it also can speed up gradient descent! Note that we can also suffer from oscillating around the minimum before settling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One solution to optimize further is using the Nesterov momentum optimization (also referenced as NAG for \"Nesterov Accelerated Gradient\"). This basically does momentum like before but considers the gradient ahead of where it actually is.\n",
    "\n",
    "$$ V_m \\leftarrow \\beta V_m - \\alpha \\nabla J(W+\\beta V_m) $$\n",
    "$$ W \\leftarrow W + V_m $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T16:38:17.221631Z",
     "start_time": "2019-12-10T16:38:13.819567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "\n",
    "#model.compile(optimizer=sgd_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Make it Go Faster with Optimizers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Normalization (Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> https://keras.io/layers/normalization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This allows speedier training so no one feature will overpower the direction down the hill\n",
    "\n",
    "Note if you use something like batch normalization, training speed can slow but converging to the minimal cost will tend to happen sooner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of taking a long time through the whole process with dataset (careful step), go through part of the dataset quicker (quick, \"drunken\" steps). Note that this means it will also take less space in memory.\n",
    "\n",
    "\"Stochastic\" == Random\n",
    "\n",
    "![](images/sgd_visualization.png)\n",
    "\n",
    "> Note: You likely will want to combine this momentum and other tweaks like learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Steps\n",
    "\n",
    "1. Take a random set (batch)\n",
    "2. Feedforward batch through model\n",
    "3. Calculate error (loss) from batch\n",
    "4. Adjust weights via backpropogagtion\n",
    "5. Repeat with all points/batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## AdaGrad & RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Quick aside, typically we don't use AdaGrad as it will tend to stop too early in complex problems (neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One problem with gradient descent is we might take too many big jumps on the steep section. **AdaGrad** and the improvement from **RMSProp** allows us to be more careful when it's steep. AdaGrad accumulates avearage gradients from all iterations while RMSProp will decay the older iterations (keeping mostly the most recent iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T17:16:37.384436Z",
     "start_time": "2019-12-10T17:16:37.178007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A quick plot of contour to draw on\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) ** 6 + np.cos(10 + y * x) \n",
    "\n",
    "x = np.linspace(1, 2., 50)\n",
    "y = np.linspace(0.5, 3.2, 40)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = -f(X, Y)\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "plt.contour(X, Y, Z, 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T17:19:20.289541Z",
     "start_time": "2019-12-10T17:19:17.346732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "# Typically rho=0.9 is a good value\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "\n",
    "#model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adam (Adaptivr Moment Estimation) Optimization and Other Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Combines momentum and RMSProp strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T17:28:02.608632Z",
     "start_time": "2019-12-10T17:28:02.603676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Typical values for Adam\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "#model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Nadam**: Basically combines Adam and Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Typical values for Nadam\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "#model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note**: Sometimes Adam just isn't good for a dataset; a good alternative is just using plain old momentum with Nesterov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Learning Rate Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Idea is that:\n",
    "\n",
    "- **high learning rate** value --> we move fast but possibly skip over the local minimum\n",
    "- **low learning rate** value --> we move slowly, maybe never getting there\n",
    "\n",
    "So there are advantages and disadvantages for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/why-not-both.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we have more epochs, we should approach our answer. We can decrease $\\alpha$ as we complete epochs, so we (hopefully) do the following: \n",
    "- If steep (large) gradient, we use a large $\\alpha$\n",
    "- If level (small) gradient, we use a small $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are other ways to implement this and customize the learning rate but here is a simple way with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "optimizer = keras.optimizers.SGD(decay=0.0001)\n",
    "\n",
    "#model.compile(optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
