{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Natural-Language-Processing-Intro\" data-toc-modified-id=\"Natural-Language-Processing-Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Natural Language Processing Intro</a></span></li><li><span><a href=\"#Challenges-of-NLP\" data-toc-modified-id=\"Challenges-of-NLP-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Challenges of NLP</a></span></li><li><span><a href=\"#The-NLP-Pipeline\" data-toc-modified-id=\"The-NLP-Pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The NLP Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Text-processing-involves-removing-the-extra-&quot;junk&quot;\" data-toc-modified-id=\"Text-processing-involves-removing-the-extra-&quot;junk&quot;-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Text processing involves removing the extra \"junk\"</a></span></li><li><span><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Feature Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Graph-representation\" data-toc-modified-id=\"Graph-representation-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Graph representation</a></span></li><li><span><a href=\"#Document-level\" data-toc-modified-id=\"Document-level-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Document level</a></span></li><li><span><a href=\"#Words-&amp;-Phrases\" data-toc-modified-id=\"Words-&amp;-Phrases-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Words &amp; Phrases</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Overall-Example-of-Pipeline\" data-toc-modified-id=\"Overall-Example-of-Pipeline-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Overall Example of Pipeline</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Natural Language Processing Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Very structured language (logic, mathematics, programming, etc) vs a natural language that is fluid, complexity, and unstructured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Computers bridge the gap by processing words & phrases (identifying parts of speech, keywords, etc.), parsing sentences (statements, questions, etc.), and more advanced techiniques like tone & sentiment analysis and document grouping/clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Challenges of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Difficult to understand meaning for a computer:\n",
    "\n",
    "> I was led to believe that the Fyre Festival would be an amazing, transcendent event - I was conned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ambiguity because of lack of **context** (meaning or *semantics*):\n",
    "\n",
    "> The pipe couldn't fit through the hole in the wall since it was too big.\n",
    "\n",
    "versus:\n",
    "\n",
    "> The pipe couldn't fit through the hole in the wall since it was too small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Text processing involves removing the extra \"junk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Can't simply feed in data unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step to NLP is to process the **text** (here I mean the text representation of the natural language being used). Then would be extracting features which we can use to model (we'll see soon how to do this given the features later in this module).\n",
    "\n",
    "In this section, we will focus on the text processing portion and some feature extraction/selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Graph representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "WordNet: https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Document level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> bag of words\n",
    ">\n",
    "> doc2vec\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Uses:\n",
    "\n",
    "+ Sentiment analysis\n",
    "+ Spam detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Words & Phrases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> word2vec\n",
    ">\n",
    "> glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Uses:\n",
    "+ Text generation\n",
    "+ Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Using numerical allows the ML algorithms we know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Overall Example of Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv('messages.csv')\n",
    "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # train classifier\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # display results\n",
    "    display_results(y_test, y_pred)\n",
    "\n",
    "\n",
    "main()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
